* This file is part of the open-lmake distribution (git@github.com:cesar-douady/open-lmake.git)
* Copyright (c) 2023 Doliam
* This program is free software: you can redistribute/modify under the terms of the GPL-v3 (https://www.gnu.org/licenses/gpl-3.0.html).
* This program is distributed WITHOUT ANY WARRANTY, without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

items :
	* normal    item : ordered by implementation priority in each section
	! difficult item : unclear how to implement it
	? idea      item : unclear that it is desirable

****************************************************************************************************
* BUGS (implemented but does not work)
****************************************************************************************************

! sometimes losing terminal colors
	- hard to reproduce
	- maybe, if reporting is done from several threads (but normally it is not)
		- then we should fix that or implement a lock

****************************************************************************************************
* LACK (not implemented but necessary for lmake semantic)
****************************************************************************************************

* automatic versioning of internal info
	- extend serdes to enumerate fields & types
	- for data base
		- Store
		- JobInfoStart
		- JobInfoEnd
		? ...
	- for cache
		- JobInfoStart
		- JobInfoEnd
		- find a way to identify LRU structure
* mimic slurm killing procedure
	- follow process hierarchy
	- recognize stdin, stdout, stderr
	- do it in 2 passes
		- as process hierarchy moves while we walk through it
		- stop during discovery pass
		- kill when everything is steady
! in autodep dlopen/ld_preload (cf man 3 dlopen)
	- handle DT_RPATH & DT_RUNPATH tags
	- handle indirect loads
! before erasing a dir, check for phony targets, not only files on disk

****************************************************************************************************
* COSMETIC (ugly as long as not implemented)
****************************************************************************************************

* generate performance metrics
	- useful/useless created jobs
	- number of non buildable nodes
	- max number of resources slots in backend
	- total number of deps
	- total number of pressure updates
* be more consise in console output
	- and more precise in recorded log
	- dates, justifications go to log while essential info is shown on screen
	- e.g. 'dep changed' on screen and actual dates (before, after) in log
	- same for manual, etc.
? consider a package for option passing
	? gnu argp
	? http://nongnu.askapache.com/argpbook/step-by-step-into-argp.pdf
? if actual_job!=conform_job, show both with warning in lshow
? report resources even when job spawn process groups
	- dont know how to do that

****************************************************************************************************
* ROBUSTNESS & MAINTENABILITY (fragile/difficult to read or maintain as long as not implemented)
****************************************************************************************************

* implement noexcept/except everywhere pertinent
* use the Path struct instead of at/file
	- everywhere applicable
* add a warning when ids reach 15/16 of their limits
* get rid of double crc (md5+xxh)
	- keep only xxh
	- superior on all metrics
! put in place a variant in Job::ReqInfo
	- to ensure no infinite rerun loop
	- for example the index of the first dep that triggered the rerun
		- this should increase at each rerun
! track disk accesses from server
	- allow direct read of makefiles
		- avoid serialization of rule_rep (but still need serialization of attributes as makefiles are not read at each lmake)
	- allow check that dynamic attributes only access what they are allowed to access
! find a use case to ensure dates are correctly handled with NFS
? if a job cannot connect to job_exec to report deps
	- note fact in a marker file
		- exit with error is not enough as it could be hidden by the job itself if in a sub-process
	- check marker file existence in job_exec
		- and retry job in that case rather than generating job in error
? split utils.hh into several smaller files in utils directory
? implement class path_?? (x, n or s) in path.hh
	- semantic : path w/ & w/o / at beginning and end
	- implement mk_lcl, mk_glb, mk_rel, mk_abs, ...
	- inherit from ::string
	- s means w/ /, n means w/o /, x means w/ or w/o /
	- no actual disk access

****************************************************************************************************
* FEATURES (not implemented and can work without)
****************************************************************************************************

*1 provide the possibility to play dynamically with resources in config
	- for entries (module,args), it means read modules after having put args in sys.argv
	- provide a sources_modules entry in lmake.config
		- a list of tuple (module,args)
		- pre-initialize to None
			- if None and lmake.sources is not populated, set it to source control
				- if git, put an entry per sub-module (including main repo)
					- with lmake.git as the module and the sub-module as arg
					- this way, only sub-modules that change are read
				- if Manifest, put an entry with lmake.manifest as the only entry
	- provide a rules_modules entry in lmake.config
		- a list of tuple (module,args)
		- pre-initialize to []
	- provide a dynamic_module entry in lmake.config
		- a tuple (module,args)
	- maintain an umap (module,args)->sources
		- include () for top level (in case there are sources directly in Lmakefile.py)
		- read-compare-update only the entries that are modified
			- the dep list to consider must include the dep list of the top level
				- as a modif of the top-level may change everything
		- consider new entry as old-empty
		- consdier old entry as new-empty
	- idem for rules
	- reread dynamic as soon as it changes
		- either upon an lmake command
		? or an electric mode with inotify
*2 implement a lshow -r to see what is running now and -B to see BOM (list of sources)
	- implement a generic walk through deps
	- use it for check_deps, which will prevent jobs post critical deps to be run
* result cache v2 (copy & link) :
	- put typeid(StartInfo,EndInfo,...) as version tag to ensure no inter-version clashes
	- 2 levels : disk level, global level
	- use link instead of copy
	- warning : only when mtime is used instead of ctime
* implement a ref/check mechanism
	- record a map file:crc under git
	- err if generated crc does not match recorded crc
	- implement "lref file crc" to record/update map
* allow dynamic attribute functions to have inherited values (passing inherited value as argument)
	- maybe not strictly necessary, but this is what is done for cmd
! support direct rebuild of deps
	- switch from Python regexprs to C++/ECMAscript regexprs (almost identical for user)
		- difficulty is that there is no named group
		- this means () from user regexprs must be counted to compute group indices
		- which in turn means to do a expr analysis (lexical or syntaxic ?) to recognize true ()'s from escaped ones
	- specify a target flag 'direct' for use by pattern
	- specify a dep    flag 'direct' for dynamic use (through ldepend)
	- pass known hidden deps to job_exec to avoid connection to server when known
	- the difficult point : manage resource deadlocks
		- suspend waiting job (tell backend job is suspended)
		- tell backend job is resumed
		- while suspended, consider resources to be freed
		- send a signal to job such as 28 (SIGWINCH) which is normally ignored so it can free expensive resources such as licences
		- then resume participates to allocation competition
! record deps during attribute computation
	- when dynamic
! implement star optional :
	- walk through nodes from best root (which means implementing "find")
	- match against regexpr
	- operate as for star in star_targets
? implement a compilation rule py->pyc
	- and use python -B
	- what about the numerous retries this approach implies ?
		- this is a use case for direct dep update
		! beware that pyc records py date
			- then pyc would be broken if py is updated steady as pyc would not be remade
			- requires a dep flag to say we are depending on date
			? or use the python crc based mechanism
? consider fuse as an autodep method
	? unclear it is faster than ptrace
		? all data traffic goes through it
		? many context switches
		? an advantage is that accesses to system files (outside the repository) are transparent
	? there must be one fuse mount for each job so as to recognize which job does the access
	? how to manage so that the job sees the repository with its nominal name
		? requires a chroot
? provide a lock mechanism in local backend
	? much like a bunch of resources w/ capacity=1
	? stored as a set
? implement prelude
	? for very short rules (.pyc, opts, ...), put script in prelude and no cmd
	? generally speaking, prelude can trigger deps and avoid rerun
	? use autodep from within server
		? it should be possible to link in such a way that only Python sees autodep, that would be ideal
		? once this is done, we may record deps for rsrcs & forbid them for deps computation
? find a way for resources to be anything
	? int/float/str/bool/None/... or list/tuple/set/dict thereof
? add a new autodep mechanism based on syscall user dispatch
	? cf man 2 prctl, PR_SET_SYSCALL_USER_DISPATCH
	? seems to be highly architecture dependent, is it worth ?

****************************************************************************************************
* OPTIMIZATIONS
****************************************************************************************************

*3 process specifically uphill
	- directly depend node->node
	- avoid creating an intermediate job
	- there are a lot of them an bring no value
*4 record dep crcs in Job rather than in Dep
	- store crc just before dep error parallel chunk
	- dont store deps after first dep error parallel chunk as they are useless
	- this way we can severely reduce the Deps size (4x if we can manage accesses)
* Improve job_exec overhead
	- pass JobRpcReply as argument to job_exec when reasonably small
	- job_exec connect to server in parallel with job execution to get connection info
	- synchronize in case gather_deps needs to connect to server (ChkDeps &co)
	- suppress acknowledge at end of job
	- defer heartbeat when it cannot connect to job
		- wait 1s+network_delay
		- to leave time to end report to be processed
		- process heartbeat generated end of job only when no other connection is pending
* there can be 1 backend thread per backend
	- with one master socket
	- and everything replicated per backend (including mutexes, tables, etc.)
	- allow several backends of same type to distribute load
* when rounding resources using config.backends.precisions
	- round to prioritize jobs
	- do not round for actual allocation
* trap close in autodep
	- so as to know when a dep was last accessed
	- and avoid too may overwrites
* gprof
* get rid of pycxx
! manage HUGE pages in store
	- does not work straight forward
	- may be use a giant map to reserve address space and allocate a growing map in there using HUGE pages
	- need to do some trials
? launch deps as soon as they are discovered
	- w/o waiting for dependent job to complete
	- for non-phony non-existent deps, else there is a risk that a steady target is modified while job is on going
		- or record close & dup so as to know when a file is no longer needed
		- gather crc before dep launch in case dep is steady
	- possibly upon declaration by user
? set an access cache in autodep
	? put only static info
	? mark target dirs & tmp as beginning of writable area -> do not cache within
	? cache accesses as long as we are not in the writable area
		? maintain table file -> Dir/Lnk(value)/FileOrNone
? replace db_date() with an index into a table
	? put db_date() in ReqInfo, which is somewhat delicate
		? or invent a new temporary struct which is not indexed by req
	? capture table at start of req with existing reqs
	? just replace in Src, a direct copy of file date by a search in this table
	? replace check with a comparison on index
	? rest of code is identical
? improve rule updating
	? when matching changes but command does not change, avoid to relaunch job
	? compute cmd checksum on its code rather than on the source to resist to cosmetic changes such as comments modifs

****************************************************************************************************
* DOC
****************************************************************************************************

* add hard limits
	- rules, targets, deps, rscrs, nodes, jobs...

****************************************************************************************************
* TESTS
****************************************************************************************************

* add a unit test for dup2
* add a unit test for sub-Lmakefile.py
* ancillary commands to unit tests
	- lshow, ...
* add a unit_test to validate n_retries
* gcov
* idx overflow
	- check with 8-bits indexes
* test crash recovery
	- including atomicity of store

****************************************************************************************************
* TOOLS
****************************************************************************************************

* consider gdb guis :
	- apt install nemiver
* consider serialization libs :
	- https://github.com/alibaba/yalantinglibs
		- https://alibaba.github.io/yalantinglibs/resource/A%20Faster%20Serialization%20Library%20Based%20on%20Compile-time%20Reflection%20and%20C++%2020.pdf
* lrepair
	- ensure ancillary file contains all necessary info to rebuild DB
		- rule crc
		- deps crc
* implement a file dump
	- put a header in files so that format can be automatically recognized
	- suitable for use in vim
! develop lmake under lmake
	- autodep must support to be audited by autodep for unit tests
	- provide a bootstrap script
? make a navigation tool based on Neo4J or a similarly complete tool
